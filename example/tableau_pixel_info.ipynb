{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixelate map\n",
    "This notebook mainly draw a pixelated map by formatting a json file  \n",
    "The NASA data used in this example can be downloaded here:  \n",
    "https://drive.google.com/file/d/17dWJQ_UxAJEYCpnw6n7bZ8aqa05DvCZT/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ev_temp_map.utils import get_lat_lon_mask\n",
    "from ev_temp_map.utils import get_temperature\n",
    "from ev_temp_map.utils import get_zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get some data for the map\n",
    "Before we draw the map, we need to have some data. Here I just copy-paste codes to count max consecutive MPID, calculate an EV score, and calculate maximum daily range loss  \n",
    "Adding more data is trivia if you follow the same paradigm of formatting the data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE_DIR = \"./data/nasa/\"\n",
    "\n",
    "START_YEAR, END_YEAR = 2010, 2020\n",
    "\n",
    "NUM_OF_YEARS = END_YEAR - START_YEAR\n",
    "\n",
    "NUM_OF_MONTHS = 12\n",
    "\n",
    "NUM_OF_DAYS = {1: 31, 2: 28, 3: 31, 4: 30, 5: 31, 6: 30, 7: 31, 8: 31,\n",
    "               9: 30, 10: 31, 11: 30, 12: 31}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, We need to use any of the data files to extract latitudes, longitudes and the land-ocean mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAT, LON, MASK = get_lat_lon_mask(DATA_FILE_DIR+\"20200101.nc4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data 1: maximum consecutive MPID (must plug-in day)  \n",
    "Algorithm: Keep two counters. One records the current consec MPID, and the other records the max consec MPID it has seen so far. After counting one day's MPID, compare the two and keep the larger one. Use `np.where` to adapt this algo to count on arrays  \n",
    "  \n",
    "Data 2: average maximum and daily range loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 Finished!\n",
      "\n",
      "Wall time: 5min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# read the scale factors\n",
    "SCALE_FACTORS = pd.read_csv(\"./data/extrapolated_factors.csv\")\n",
    "PERCENT_LOSS = SCALE_FACTORS[\"Range Loss\"].to_numpy()\n",
    "\n",
    "# max_MPID will record the max MPID of all places in a year\n",
    "max_MPID = np.ndarray(shape=(len(LAT), len(LON)))\n",
    "# curr_MPID will count the consecutive MPID we have seen so far (the counter)\n",
    "curr_MPID = np.ndarray(shape=(len(LAT), len(LON)))\n",
    "# each_year_avg_loss will record each year's avgerage daily range loss\n",
    "each_year_avg_loss = np.zeros(shape=(NUM_OF_YEARS, len(LAT), len(LON)))\n",
    "# max_loss will record the maximum daily range loss\n",
    "max_loss = np.zeros(shape=(len(LAT), len(LON)))\n",
    "\n",
    "for year in range(START_YEAR, END_YEAR):\n",
    "    print(year, end=' ')\n",
    "\n",
    "    # keep track of the number of days\n",
    "    i = 0\n",
    "    # yearly_loss will record each day's range loss of this year\n",
    "    yearly_loss = np.zeros(shape=(365, len(LAT), len(LON)))\n",
    "\n",
    "    for month in range(1, NUM_OF_MONTHS+1):\n",
    "        for day in range(1, NUM_OF_DAYS[month]+1):\n",
    "            date = \"{}{:02d}{:02d}\".format(year, month, day)\n",
    "            filepath = DATA_FILE_DIR + date + '.nc4'\n",
    "            date_temp = get_temperature(filepath)\n",
    "\n",
    "            # if this place has MPID on this day (temp<253.15K),\n",
    "            # then curr_MPID+1\n",
    "            # else, this place has no MPID on this day, which means not\n",
    "            # consecutive, so we reset the counter to 0;\n",
    "            curr_MPID = np.where(date_temp < 253.15, curr_MPID+1, 0)\n",
    "            # this is equivalent to A = max(A, B)\n",
    "            max_MPID = np.where(curr_MPID > max_MPID, curr_MPID, max_MPID)\n",
    "\n",
    "            # get the range loss of each day in this year\n",
    "            date_temp = np.round(date_temp-273.15, decimals=1)  # convert to oC\n",
    "            # use the temperature difference as index. e.g. if temperature is\n",
    "            # -12.5 oC, then its range loss will be the (-12.5+100)*10=875th\n",
    "            # element in the percent_loss array\n",
    "            # \"+100\" means \"-(-100)\", \"*10\" means \"/0.1\"\n",
    "            index = (date_temp+100)*10\n",
    "            yearly_loss[i] = PERCENT_LOSS[index.astype(int)]\n",
    "\n",
    "            i += 1\n",
    "\n",
    "    # calculate the yearly average daily range loss\n",
    "    each_year_avg_loss[year-START_YEAR] = yearly_loss.mean(axis=0)\n",
    "    # calculate the yearly maximum daily range loss\n",
    "    # NOTE: range loss is a negative value, so we use min()\n",
    "    yearly_max_loss = yearly_loss.min(axis=0)\n",
    "    max_loss = np.where(yearly_max_loss < max_loss, yearly_max_loss, max_loss)\n",
    "\n",
    "print('Finished!\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data 3: EV score  \n",
    "EV score is simply converted from daily range loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the daily average range loss\n",
    "avg_loss = each_year_avg_loss.mean(axis=0)\n",
    "\n",
    "# round the maximum daily range loss to 1 decimal\n",
    "max_loss = np.round(max_loss, decimals=1)\n",
    "\n",
    "# calculate score and round it to 1 decimal\n",
    "avg_score = (avg_loss-avg_loss.min())/(avg_loss.max()-avg_loss.min())*100\n",
    "avg_score = np.round(avg_score, decimals=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the map with pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format a JSON file  \n",
    "Each pixel is a rectangle shape (Polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "json_file = {'features': [], 'type': 'FeatureCollection'}\n",
    "for i in range(len(LAT)):\n",
    "    for j in range(len(LON)):\n",
    "        if (not MASK[i, j]):\n",
    "            feature = {'geometry': {'coordinates': [], 'type': 'Polygon'},\n",
    "                       'properties': {},\n",
    "                       'type': 'Feature'}\n",
    "\n",
    "            # the shape boundary of one pixel. It is represented in a list\n",
    "            pixel = [[[LON[j]-.125, LAT[i]-.125],\n",
    "                      [LON[j]-.125, LAT[i]+.125],\n",
    "                      [LON[j]+.125, LAT[i]+.125],\n",
    "                      [LON[j]+.125, LAT[i]-.125]]]\n",
    "            feature['geometry']['coordinates'] = pixel\n",
    "\n",
    "            # if you want to add more info/values just follow this tempLATe:\n",
    "            # feature['properties']['YOUR FEATURE NAME'] = YOUR VALUE\n",
    "            feature['properties']['EV Zone'] = get_zone(avg_score[i, j])\n",
    "            feature['properties']['Score'] = avg_score[i, j]\n",
    "            feature['properties']['Max consecutive MPID'] = int(max_MPID[i, j])\n",
    "            feature['properties']['Max daily range loss'] = max_loss[i, j]\n",
    "\n",
    "            # append this pixel to the feature list\n",
    "            json_file['features'].append(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the map in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./geojson_files\", exist_ok=True)\n",
    "with open('./geojson_files/pixel_data.json', 'w') as outfile:\n",
    "    json.dump(json_file, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
