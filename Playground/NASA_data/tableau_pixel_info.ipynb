{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixelate map\n",
    "This notebook mainly draw a pixelated map by formatting a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get some data for the map\n",
    "Before we draw the map, we need to have some data. Here I just copy-paste codes to count max consecutive MPID, calculate an EV score, and calculate maximum daily range loss  \n",
    "Adding more data is trivia if you follow the same paradigm of formatting the data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE_DIR = \"./data/nasa/\"\n",
    "\n",
    "START_YEAR, END_YEAR = 2010, 2020\n",
    "\n",
    "NUM_OF_YEARS = END_YEAR - START_YEAR\n",
    "\n",
    "NUM_OF_MONTHS = 12\n",
    "\n",
    "NUM_OF_DAYS = {1: 31, 2: 28, 3: 31, 4: 30, 5: 31, 6: 30, 7: 31, 8: 31, 9: 30, 10: 31, 11: 30, 12: 31}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source data format is `netCDF4`.  \n",
    "First, We need to use any of the source files to extract latitudes and longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = nc.Dataset(DATA_FILE_DIR+'20110101.nc4')\n",
    "\n",
    "lat = file.variables['lat'][:].filled()\n",
    "lon = file.variables['lon'][:].filled()\n",
    "LON = len(lon)\n",
    "LAT = len(lat)\n",
    "\n",
    "# we will use this mask later\n",
    "mask = file.variables['AvgSurfT_tavg'][0].mask\n",
    "\n",
    "# remember to close opened files after use\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tmp(filepath):\n",
    "    \"\"\"\n",
    "    This function extracts temperature data from the given filepath\n",
    "    \n",
    "    # Arguements:\n",
    "        filepath: A string that specifies the file to be read\n",
    "    # Returns:\n",
    "        The data temperature in the file\n",
    "    \"\"\"\n",
    "    assert os.path.isfile(filepath), '{} does not exist!'.format(filepath)\n",
    "    \n",
    "    file = nc.Dataset(filepath)\n",
    "    temperature = file.variables['AvgSurfT_tavg'][0]\n",
    "    file.close()\n",
    "    \n",
    "    return temperature.filled(273.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data 1: maximum consecutive MPID (must plug-in day)  \n",
    "Algorithm: Keep two counters. One records the current consec MPID, and the other records the max consec MPID it has seen so far. After counting one day's MPID, compare the two and keep the larger one. Use `np.where` to adapt this algo to count on arrays  \n",
    "  \n",
    "Data 2: average maximum and daily range loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 Finished!\n",
      "\n",
      "Wall time: 5min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# read the scale factors\n",
    "scale_factors = pd.read_csv(\"./data/fitted_factors.csv\")\n",
    "percent_loss = scale_factors[\"Range Loss\"].to_numpy()\n",
    "\n",
    "# max_MPID will record the max MPID of all places in a year\n",
    "max_MPID = np.ndarray(shape=(LAT, LON))\n",
    "# curr_MPID will count the consecutive MPID we have seen so far (the counter)\n",
    "curr_MPID = np.ndarray(shape=(LAT, LON))\n",
    "# each_year_avg_loss will record each year's avgerage daily range loss\n",
    "each_year_avg_loss = np.zeros(shape=(NUM_OF_YEARS, LAT, LON))\n",
    "# max_loss will record the maximum daily range loss\n",
    "max_loss = np.zeros(shape=(LAT, LON))\n",
    "\n",
    "for year in range(START_YEAR, END_YEAR):\n",
    "    print(year, end=' ')\n",
    "    \n",
    "    # keep track of the number of days\n",
    "    i = 0\n",
    "    # yearly_loss will record each day's range loss of this year\n",
    "    yearly_loss = np.zeros(shape=(365, LAT, LON))\n",
    "    \n",
    "    for month in range(1, NUM_OF_MONTHS+1):\n",
    "        for day in range(1, NUM_OF_DAYS[month]+1):\n",
    "            date = \"{}{:02d}{:02d}\".format(year, month, day)\n",
    "            filepath = DATA_FILE_DIR + date + '.nc4'\n",
    "            date_temp = get_tmp(filepath)\n",
    "            \n",
    "            # if this place has MPID on this day (temp<253.15K), then curr_MPID+1\n",
    "            # else, this place has no MPID on this day, which means not consecutive, so we reset the counter to 0;\n",
    "            curr_MPID = np.where(date_temp<253.15, curr_MPID+1, 0) # 253.15 K = -20 oC\n",
    "            # this is equivalent to A = max(A, B)\n",
    "            max_MPID = np.where(curr_MPID>max_MPID, curr_MPID, max_MPID)\n",
    "            \n",
    "            # get the range loss of each day in this year\n",
    "            date_temp = np.round(date_temp-273.15, decimals=1) # convert to oC\n",
    "            # use the temperature difference as index. e.g. if temperature is -12.5 oC, then its range loss will\n",
    "            # be the (-12.5+100)*10=875th element in the percent_loss array\n",
    "            # \"+100\" means \"-(-100)\", \"*10\" means \"/0.1\"\n",
    "            index = (date_temp+100)*10\n",
    "            yearly_loss[i] = percent_loss[index.astype(int)]\n",
    "            \n",
    "            i += 1\n",
    "    \n",
    "    # calculate the yearly average daily range loss\n",
    "    each_year_avg_loss[year-START_YEAR] = yearly_loss.mean(axis=0)\n",
    "    # calculate the yearly maximum daily range loss\n",
    "    # NOTE: range loss is a negative value, so we use min()\n",
    "    yearly_max_loss = yearly_loss.min(axis=0)\n",
    "    max_loss = np.where(yearly_max_loss<max_loss, yearly_max_loss, max_loss)\n",
    "\n",
    "print('Finished!\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data 3: EV score  \n",
    "EV score is simply converted from daily range loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the daily average range loss\n",
    "avg_loss = each_year_avg_loss.mean(axis=0)\n",
    "\n",
    "# calculate score and round it to 1 decimal\n",
    "avg_score = (avg_loss - avg_loss.min()) / (avg_loss.max() - avg_loss.min()) * 100\n",
    "avg_score = np.round(avg_score, decimals=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the map with pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zone(score):\n",
    "    \"\"\"\n",
    "    A simple function to return the corresponding zone of the given score\n",
    "    \"\"\"\n",
    "    assert 0 <= score <= 100, \"Score {} is out of valid range [0, 100]\".format(score)\n",
    "    \n",
    "    if score < 10:\n",
    "        return \"0-10\"\n",
    "    elif score < 20:\n",
    "        return \"10-20\"\n",
    "    elif score < 30:\n",
    "        return \"20-30\"\n",
    "    elif score < 40:\n",
    "        return \"30-40\"\n",
    "    elif score < 50:\n",
    "        return \"40-50\"\n",
    "    elif score < 60:\n",
    "        return \"50-60\"\n",
    "    elif score < 70:\n",
    "        return \"60-70\"\n",
    "    elif score < 80:\n",
    "        return \"70-80\"\n",
    "    elif score < 90:\n",
    "        return \"80-90\"\n",
    "    else:\n",
    "        return \"90-100\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format a JSON file  \n",
    "Each pixel is a rectangle shape (Polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "json_file = {'features':[], 'type': 'FeatureCollection'}\n",
    "for i in range(LAT):\n",
    "    for j in range(LON):\n",
    "        if (not mask[i, j]):\n",
    "            feature = {'geometry':{'coordinates':[], 'type': 'Polygon'},\n",
    "                       'properties':{},\n",
    "                       'type': 'Feature'}\n",
    "            \n",
    "            # the shape boundary of one pixel. It is represented in a list\n",
    "            pixel = [[[lon[j]-.125,lat[i]-.125],\n",
    "                      [lon[j]-.125,lat[i]+.125],\n",
    "                      [lon[j]+.125,lat[i]+.125],\n",
    "                      [lon[j]+.125,lat[i]-.125],\n",
    "                      [lon[j]-.125,lat[i]-.125]]]\n",
    "            feature['geometry']['coordinates'] = pixel\n",
    "            \n",
    "            # if you want to add more information/values just follow this template:\n",
    "            # feature['properties']['YOUR FEATURE NAME'] = YOUR VALUE\n",
    "            feature['properties']['EV Zone'] = get_zone(avg_score[i,j])\n",
    "            feature['properties']['Score'] = avg_score[i,j]\n",
    "            feature['properties']['Max consecutive MPID'] = int(max_MPID[i,j])\n",
    "            feature['properties']['Max daily range loss'] = max_loss[i,j]\n",
    "            \n",
    "            # append this pixel to the feature list\n",
    "            json_file['features'].append(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the map in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./geojson_files\", exist_ok=True)\n",
    "with open('./geojson_files/pixel_data_1.json', 'w') as outfile:\n",
    "    json.dump(json_file, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
